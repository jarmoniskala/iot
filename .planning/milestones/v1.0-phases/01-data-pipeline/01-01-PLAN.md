---
phase: 01-data-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - supabase/migrations/001_schema.sql
  - supabase/migrations/002_functions.sql
  - supabase/functions/ingest-sensors/index.ts
  - supabase/seed.sql
autonomous: true
requirements:
  - PIPE-01
  - PIPE-02

must_haves:
  truths:
    - "Ruuvi Station Android app can POST sensor readings to the ingest-sensors edge function endpoint and receive a success response"
    - "Valid sensor readings are stored in the sensor_readings table with all fields (temperature, humidity, pressure, battery, RSSI, movement counter, TX power, accel, sequence, data format, sensor name, raw payload)"
    - "Duplicate readings (same MAC + timestamp) are rejected silently -- the app receives a success response, but no duplicate row is created, and the duplicate is logged"
    - "Outlier readings (values outside physical ranges) are stored but flagged with is_outlier=true and outlier_reason"
    - "New/unknown RuuviTags are accepted automatically -- any MAC address can submit readings"
    - "Rate limiting prevents abuse (60 req/min per deviceId) without blocking normal Ruuvi Station usage"
  artifacts:
    - path: "supabase/migrations/001_schema.sql"
      provides: "All database tables: sensor_config, sensor_readings (partitioned), weather_observations (partitioned), ingestion_log"
      contains: "PARTITION BY RANGE"
    - path: "supabase/migrations/002_functions.sql"
      provides: "Database functions for partition creation and storage monitoring"
      contains: "create_monthly_partition"
    - path: "supabase/functions/ingest-sensors/index.ts"
      provides: "HTTP POST handler for Ruuvi Station data forwarding"
      exports: ["Deno.serve"]
    - path: "supabase/seed.sql"
      provides: "Initial sensor_config entries for 4 known sensors and initial partitions"
      contains: "INSERT INTO sensor_config"
  key_links:
    - from: "supabase/functions/ingest-sensors/index.ts"
      to: "sensor_readings table"
      via: "supabase.from('sensor_readings').insert()"
      pattern: "from.*sensor_readings.*insert"
    - from: "supabase/functions/ingest-sensors/index.ts"
      to: "ingestion_log table"
      via: "supabase.from('ingestion_log').insert()"
      pattern: "from.*ingestion_log.*insert"
    - from: "supabase/migrations/001_schema.sql"
      to: "sensor_readings table"
      via: "UNIQUE INDEX for deduplication"
      pattern: "idx_sensor_readings_dedup"
---

<objective>
Create the complete Supabase database schema and the Ruuvi sensor ingestion edge function.

Purpose: Establish the data foundation that all subsequent work depends on -- tables for sensor readings, weather observations, sensor config, and ingestion logs, plus the edge function that receives and validates Ruuvi Station Android app data.

Output: Four SQL migration files defining the full schema, a Deno edge function handling sensor ingestion with validation/dedup/outlier detection/rate limiting, and seed data for the initial 4 sensors.
</objective>

<execution_context>
@/Users/jarmoniskala/.claude/get-shit-done/workflows/execute-plan.md
@/Users/jarmoniskala/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-data-pipeline/01-CONTEXT.md
@.planning/phases/01-data-pipeline/01-RESEARCH.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Database schema and utility functions</name>
  <files>supabase/migrations/001_schema.sql, supabase/migrations/002_functions.sql, supabase/seed.sql</files>
  <action>
Create the Supabase project structure and database schema.

**001_schema.sql -- All tables:**

1. `sensor_config` table for MAC-to-room mapping with timestamp-based assignment history:
   - `id` bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
   - `mac_address` text NOT NULL
   - `display_name` text NOT NULL (preserved from Ruuvi Station app `name` field)
   - `room_name` text (nullable -- may not be assigned yet)
   - `assigned_at` timestamptz NOT NULL DEFAULT now()
   - `unassigned_at` timestamptz (NULL = currently active)
   - `notes` text
   - `created_at` timestamptz DEFAULT now()
   - Index on `mac_address`, partial index on active assignments (`WHERE unassigned_at IS NULL`)

2. `sensor_readings` table (monthly partitioned by `measured_at`):
   - `id` bigint GENERATED BY DEFAULT AS IDENTITY
   - `mac_address` text NOT NULL
   - `measured_at` timestamptz NOT NULL
   - `temperature` double precision
   - `humidity` double precision
   - `pressure` double precision (stored in Pascals as received from Ruuvi -- Pa, not hPa)
   - `battery_voltage` double precision
   - `rssi` integer
   - `movement_counter` integer
   - `tx_power` integer
   - `accel_x` double precision, `accel_y` double precision, `accel_z` double precision
   - `measurement_sequence` integer
   - `data_format` integer
   - `sensor_name` text (preserved raw name from Ruuvi Station app)
   - `is_outlier` boolean DEFAULT false
   - `outlier_reason` text
   - `raw_payload` jsonb (complete tag object for debugging)
   - `created_at` timestamptz DEFAULT now()
   - PRIMARY KEY `(measured_at, id)` (partition key must be in PK)
   - UNIQUE INDEX on `(mac_address, measured_at)` for deduplication

3. `weather_observations` table (monthly partitioned by `observed_at`):
   - `id` bigint GENERATED BY DEFAULT AS IDENTITY
   - `observed_at` timestamptz NOT NULL
   - `fmisid` integer NOT NULL DEFAULT 100968
   - `temperature` double precision (Celsius)
   - `wind_speed` double precision (m/s, 10-min avg)
   - `wind_gust` double precision (m/s, 10-min)
   - `wind_direction` double precision (degrees)
   - `humidity` double precision (%)
   - `dew_point` double precision (Celsius)
   - `precipitation_1h` double precision (mm)
   - `precipitation_intensity` double precision (mm/h, 10-min)
   - `snow_depth` double precision (cm)
   - `pressure` double precision (hPa, sea-level)
   - `visibility` double precision (m)
   - `cloud_cover` double precision (oktas 0-8)
   - `weather_code` double precision (WMO 4680)
   - `raw_values` text (original space-separated string for debugging)
   - `created_at` timestamptz DEFAULT now()
   - PRIMARY KEY `(observed_at, id)`
   - UNIQUE INDEX on `(fmisid, observed_at)` for deduplication

4. `ingestion_log` table (NOT partitioned -- small table):
   - `id` bigint GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY
   - `source` text NOT NULL ('ruuvi' or 'fmi')
   - `status` text NOT NULL ('success', 'error', 'duplicate', 'rate_limited')
   - `readings_count` integer DEFAULT 0
   - `duplicates_count` integer DEFAULT 0
   - `outliers_count` integer DEFAULT 0
   - `error_message` text
   - `details` jsonb
   - `created_at` timestamptz DEFAULT now()
   - Index on `(source, created_at DESC)`

5. Create DEFAULT partitions for both `sensor_readings` and `weather_observations` as safety nets.

6. Create initial monthly partitions for current month (2026-02) and next month (2026-03) for both partitioned tables.

**002_functions.sql -- Database functions:**

1. `create_monthly_partition(table_name text, target_date date DEFAULT now()::date)` -- idempotent PL/pgSQL function that creates a monthly partition using `CREATE TABLE IF NOT EXISTS`. Partition naming: `{table_name}_YYYY_MM`. Creates partition for the given date's month.

2. `get_database_size_mb()` -- returns current database size in MB as numeric.

3. `get_table_sizes()` -- returns table name, size in MB, and row estimate for all user tables, ordered by size descending.

**seed.sql -- Initial data:**

Insert 4 sensor_config entries for the known sensors:
- Bedroom sensor (MAC placeholder -- user will update)
- Living room sensor (MAC placeholder)
- Kid's room sensor (MAC placeholder)
- Outdoors sensor (MAC placeholder, notes: "Will move to office later")

Use placeholder MACs like `XX:XX:XX:XX:XX:01` through `XX:XX:XX:XX:XX:04` with a SQL comment explaining the user should update these with real MACs after the first successful POST.

Initialize the Supabase project directory structure: ensure `supabase/functions/` and `supabase/migrations/` directories exist.
  </action>
  <verify>
Review the SQL files for:
- All 4 tables created with correct column types
- Both partitioned tables have DEFAULT partitions
- Current month + next month partitions created for both tables
- Unique indexes exist for deduplication
- `create_monthly_partition` function is idempotent (uses IF NOT EXISTS)
- `get_database_size_mb` and `get_table_sizes` functions exist
- seed.sql has 4 sensor_config entries
- No syntax errors in SQL (check for missing semicolons, unbalanced parentheses)
  </verify>
  <done>
All database tables (sensor_config, sensor_readings, weather_observations, ingestion_log) defined with correct columns, types, indexes, and constraints. Partitioned tables have DEFAULT + current + next month partitions. Utility functions for partition creation and storage monitoring exist. Seed data provides initial sensor config entries.
  </done>
</task>

<task type="auto">
  <name>Task 2: Ruuvi sensor ingestion edge function</name>
  <files>supabase/functions/ingest-sensors/index.ts</files>
  <action>
Create the Deno edge function that handles HTTP POST from Ruuvi Station Android app.

**Imports:**
```typescript
import { createClient } from "npm:@supabase/supabase-js@2";
```

**Handler structure (Deno.serve):**

1. **CORS handling:** Return 200 on OPTIONS with appropriate headers (Access-Control-Allow-Origin: *, Allow-Methods: POST, OPTIONS, Allow-Headers: Content-Type, Authorization, apikey).

2. **Method check:** Only accept POST. Return 405 for other methods.

3. **Authentication:** Verify the request has an Authorization header with a Bearer token matching the Supabase anon key. Use `Deno.env.get("SUPABASE_ANON_KEY")` for comparison. Return 401 if missing or invalid. NOTE: The Ruuvi Station app will send the anon key as the auth token.

4. **Rate limiting:** In-memory Map keyed by `deviceId` from payload. 60 requests per minute window. If rate-limited, return 429 with `{ ok: false, error: "rate_limited" }` and log to ingestion_log with status 'rate_limited'.

5. **Parse payload:** Extract `tags` array from request body. The Ruuvi Station Android app sends `{ tags: [...], deviceId: "...", time: "...", ... }`. If `tags` is missing or not an array, return 400.

6. **Process each tag in the `tags` array:**

   a. **Extract fields** from the tag object:
      - `mac_address` from `tag.id`
      - `measured_at` from `tag.updateAt` (parse as Date -- format is ISO-ish with timezone like "2024-01-15T10:30:00.000+0200")
      - `temperature` from `tag.temperature`
      - `humidity` from `tag.humidity`
      - `pressure` from `tag.pressure` (keep as Pascals -- do NOT convert)
      - `battery_voltage` from `tag.voltage`
      - `rssi` from `tag.rssi`
      - `movement_counter` from `tag.movementCounter`
      - `tx_power` from `tag.txPower`
      - `accel_x/y/z` from `tag.accelX/Y/Z`
      - `measurement_sequence` from `tag.measurementSequenceNumber`
      - `data_format` from `tag.dataFormat`
      - `sensor_name` from `tag.name`
      - `raw_payload` = entire tag object as JSONB

   b. **Validate required fields:** `mac_address` and `measured_at` must be present and valid. Skip the tag (don't insert, log error) if missing.

   c. **Outlier detection** using range-based checks per research recommendations:
      - Temperature: -40 to 60 C
      - Humidity: 0 to 100 %
      - Pressure: 50000 to 115000 Pa
      - Battery voltage: 1.6 to 3.65 V
      If any value is outside range, set `is_outlier = true` and `outlier_reason` to the first failing check (e.g., "temperature_out_of_range"). Store the reading anyway.

   d. **Insert** using `supabase.from("sensor_readings").insert(...)`. Use the Supabase client initialized with `SUPABASE_SERVICE_ROLE_KEY` (bypasses RLS).

   e. **Handle duplicate** (unique constraint violation on mac_address + measured_at): Catch the error (Postgres error code 23505), count it as a duplicate, do not re-throw. This satisfies the "reject silently, return success" requirement.

   f. **Auto-register unknown sensors:** After successful insert, check if the MAC exists in `sensor_config`. If not, insert a new entry with `display_name = tag.name` (or "Unknown Sensor" if name is empty/null), `room_name = null`, `assigned_at = now()`. This enables "new sensors show up automatically."

7. **Log ingestion metrics:** After processing all tags, insert one `ingestion_log` entry with:
   - `source: 'ruuvi'`
   - `status: 'success'` (or 'error' if all tags failed)
   - `readings_count`: number of successfully inserted readings
   - `duplicates_count`: number of duplicate rejections
   - `outliers_count`: number of outlier-flagged readings
   - `details`: `{ deviceId, tagCount: tags.length }` as JSONB

8. **Response:** Return JSON `{ ok: true, accepted: N, duplicates: N, outliers: N }` with HTTP 200. Use status-only format per discretion recommendation -- do not echo back the payload.

**Error handling:** Wrap the entire handler in try/catch. On unexpected errors, log to ingestion_log with status 'error' and error_message, return 500 with `{ ok: false, error: "internal_error" }`.

**Important implementation notes:**
- Use `Deno.env.get("SUPABASE_URL")` and `Deno.env.get("SUPABASE_SERVICE_ROLE_KEY")` -- these are pre-populated in Supabase Edge Functions.
- Do NOT use `esm.sh` or `deno.land/x` imports -- use `npm:` prefix per current Supabase standards.
- Pressure is stored in Pascals as received. Do not convert.
- The `tags` array is at the ROOT of the payload, not nested under `data.tags`.
  </action>
  <verify>
Review the edge function code for:
- Correct import syntax (`npm:@supabase/supabase-js@2`)
- CORS handling on OPTIONS
- Rate limiting implementation (Map-based, 60/min per deviceId)
- All Ruuvi tag fields mapped correctly (id->mac_address, updateAt->measured_at, etc.)
- Outlier detection with the 4 range checks
- Duplicate handling catches unique constraint error (code 23505) without throwing
- Auto-registration of unknown MACs in sensor_config
- Ingestion logging with counts
- Response format: `{ ok, accepted, duplicates, outliers }`
- Uses SUPABASE_SERVICE_ROLE_KEY (not anon key) for DB operations
- No esm.sh or deno.land imports
  </verify>
  <done>
The ingest-sensors edge function accepts HTTP POST from Ruuvi Station Android app, validates and processes all tags, handles duplicates silently, flags outliers, auto-registers unknown sensors, logs metrics, and returns a status-only response. Rate limiting prevents abuse at 60 req/min per device.
  </done>
</task>

</tasks>

<verification>
1. SQL migrations are syntactically valid and create all required tables, indexes, and functions
2. Edge function handles the documented Ruuvi Station payload format correctly
3. Deduplication works via unique constraint on (mac_address, measured_at)
4. Outlier detection flags but does not reject readings
5. Unknown sensors are auto-registered in sensor_config
6. Ingestion metrics are logged for every request
7. All files follow the recommended project structure from research
</verification>

<success_criteria>
- All 4 database tables exist with correct schemas (sensor_config, sensor_readings, weather_observations, ingestion_log)
- sensor_readings and weather_observations are monthly-partitioned with DEFAULT + Feb 2026 + Mar 2026 partitions
- Partition creation and storage monitoring functions exist
- ingest-sensors edge function correctly maps all Ruuvi Station fields, validates, detects outliers, handles duplicates, rate-limits, auto-registers sensors, and logs metrics
- Seed data provides initial sensor config for 4 known sensors
</success_criteria>

<output>
After completion, create `.planning/phases/01-data-pipeline/01-01-SUMMARY.md`
</output>
